{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 25,
>>>>>>> 5b64702 (preprocess update)
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emil-telmanyi_bwv1001_mov1\n",
      "48000 4048000\n",
      "emil-telmanyi_bwv1001_mov2\n",
      "4048000 9712000\n",
      "emil-telmanyi_bwv1001_mov3\n",
      "9712000 13360000\n",
      "emil-telmanyi_bwv1001_mov4\n",
      "13360000 17344000\n",
      "emil-telmanyi_bwv1002_mov1\n",
      "0 3120000\n",
      "emil-telmanyi_bwv1002_mov2\n",
      "3120000 4720000\n",
      "emil-telmanyi_bwv1002_mov3\n",
      "4720000 6448000\n",
      "emil-telmanyi_bwv1002_mov4\n",
      "6448000 8304000\n",
      "emil-telmanyi_bwv1002_mov5\n",
      "8304000 11088000\n",
      "emil-telmanyi_bwv1002_mov6\n",
      "11088000 13168000\n",
      "emil-telmanyi_bwv1002_mov7\n",
      "13168000 15360000\n",
      "emil-telmanyi_bwv1002_mov8\n",
      "15360000 17296000\n",
      "emil-telmanyi_bwv1003_mov1\n",
      "0 4112000\n",
      "emil-telmanyi_bwv1003_mov2\n",
      "4112000 12528000\n",
      "emil-telmanyi_bwv1003_mov3\n",
      "12528000 15952000\n",
      "emil-telmanyi_bwv1003_mov4\n",
      "15968000 18816000\n",
      "emil-telmanyi_bwv1004_mov1\n",
      "0 2176000\n",
      "emil-telmanyi_bwv1004_mov2\n",
      "2176000 3792000\n",
      "emil-telmanyi_bwv1004_mov3\n",
      "3792000 6032000\n",
      "emil-telmanyi_bwv1004_mov4\n",
      "6032000 8336000\n",
      "emil-telmanyi_bwv1005_mov1\n",
      "0 4832000\n",
      "emil-telmanyi_bwv1005_mov2\n",
      "4832000 15760000\n",
      "emil-telmanyi_bwv1005_mov3\n",
      "15760000 19120000\n",
      "emil-telmanyi_bwv1005_mov4\n",
      "19120000 21856000\n",
      "emil-telmanyi_bwv1006_mov1\n",
      "0 3568000\n",
      "emil-telmanyi_bwv1006_mov2\n",
      "3568000 7952000\n",
      "emil-telmanyi_bwv1006_mov3\n",
      "7952000 11392000\n",
      "emil-telmanyi_bwv1006_mov4\n",
      "11392000 13360000\n",
      "emil-telmanyi_bwv1006_mov5\n",
      "13360000 15152000\n",
      "emil-telmanyi_bwv1006_mov6\n",
      "15152000 16576000\n",
      "emil-telmanyi_bwv1006_mov7\n",
      "16576000 18464000\n",
      "ray-chen_bwv1004_mov5\n",
      "16000 13184000\n",
      "karen-gomyo_bwv1006_mov1\n",
      "16000 3536000\n",
      "karen-gomyo_bwv1006_mov2\n",
      "3584000 7680000\n",
      "karen-gomyo_bwv1006_mov3\n",
      "7728000 10672000\n",
      "karen-gomyo_bwv1006_mov4\n",
      "10704000 12528000\n",
      "karen-gomyo_bwv1006_mov5\n",
      "12528000 14272000\n",
      "karen-gomyo_bwv1006_mov4-2\n",
      "14272000 15200000\n",
      "karen-gomyo_bwv1006_mov6\n",
      "15248000 16624000\n",
      "karen-gomyo_bwv1006_mov7\n",
      "16624000 18272000\n",
      "john-garner_bwv1002_mov1\n",
      "0 3328000\n",
      "john-garner_bwv1002_mov2\n",
      "0 3024000\n",
      "john-garner_bwv1002_mov3\n",
      "0 3232000\n",
      "john-garner_bwv1002_mov4\n",
      "0 2256000\n",
      "john-garner_bwv1002_mov5\n",
      "0 2032000\n",
      "john-garner_bwv1002_mov6\n",
      "16000 1696000\n",
      "john-garner_bwv1002_mov7\n",
      "0 2256000\n",
      "john-garner_bwv1002_mov8\n",
      "0 2224000\n",
      "silei-li_bwv1003_mov1\n",
      "80000 3888000\n",
      "silei-li_bwv1003_mov2\n",
      "3920000 11968000\n",
      "kinga-augustyn_bwv1005_mov2\n",
      "16000 8704000\n",
      "oliver-colbentson_bwv1006_mov1\n",
      "0 3376000\n",
      "oliver-colbentson_bwv1006_mov3\n",
      "96000 3072000\n",
      "oliver-colbentson_bwv1006_mov4\n",
      "0 1808000\n",
      "oliver-colbentson_bwv1006_mov5\n",
      "0 1776000\n",
      "oliver-colbentson_bwv1006_mov6\n",
      "0 1520000\n",
      "oliver-colbentson_bwv1006_mov7\n",
      "0 1888000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Define the paths to the data files and folders\n",
    "dataset_folder_path = './data/bach-violin-dataset-v1.0/'\n",
    "audio_csv_path = os.path.join(dataset_folder_path, 'audio.csv')\n",
    "info_csv_path = os.path.join(dataset_folder_path, 'info.csv')\n",
    "audio_folder_path = os.path.join(dataset_folder_path, 'audio')\n",
    "alignments_folder_path = os.path.join(dataset_folder_path, 'alignments')\n",
    "notes_folder_path = os.path.join(dataset_folder_path, 'notes')\n",
    "\n",
    "# output folder\n",
    "output_folder_path = './data/bv_processed2'\n",
    "outuput_audio = os.path.join(output_folder_path, 'audio')\n",
    "output_synthesized = os.path.join(output_folder_path, 'synthesized') # synthesized piano roll\n",
    "output_proll = os.path.join(output_folder_path, 'proll') \n",
    "\n",
    "# Load the audio metadata from the audio.csv file into a pandas DataFrame\n",
    "audio_metadata = pd.read_csv(audio_csv_path)\n",
    "\n",
    "# Load the performance metadata from the info.csv file into a pandas DataFrame\n",
    "performance_metadata = pd.read_csv(info_csv_path)\n",
    "\n",
    "# Loop through the rows of the performance metadata DataFrame\n",
    "for _, row in performance_metadata.iterrows():\n",
    "    # row has the following fields:\n",
    "    # filename,collection,violinist,violinist_name,work,title,mov,movement,source_filename,start,end,length,repeat1,repeat2,score_filename,baroque_tuning\n",
    "\n",
    "    # load audio file\n",
    "    audio_filename = row['source_filename']\n",
    "    if not audio_filename.endswith('.mp3'):\n",
    "        continue\n",
    "\n",
    "    print(row['filename'])\n",
    "\n",
    "    # audio collection\n",
    "    audio_collection = row['collection']\n",
    "\n",
    "    # path to audio file\n",
    "    audio_path = os.path.join(audio_folder_path, audio_collection, audio_filename)\n",
    "\n",
    "    # load audio file\n",
    "    waveform, sample_rate = torchaudio.load(audio_path)\n",
    "\n",
    "    # downsample and convert to mono\n",
    "    waveform = torchaudio.transforms.Resample(sample_rate, 16000)(waveform)\n",
    "    waveform = waveform.mean(0, keepdim=True)\n",
    "\n",
    "    # trim the waveform based on movement start and end\n",
    "    # start and end are in the format \"h:mm:ss\"\n",
    "    start = row['start']\n",
    "    end = row['end']\n",
    "\n",
    "    # start in seconds\n",
    "    start = start.split(':')\n",
    "    start = int(start[0]) * 3600 + int(start[1]) * 60 + int(start[2])\n",
    "\n",
    "    # end in seconds\n",
    "    end = end.split(':')\n",
    "    end = int(end[0]) * 3600 + int(end[1]) * 60 + int(end[2])\n",
    "\n",
    "    # trim the waveform\n",
    "    start = int(start * 16000)\n",
    "    end = int(end * 16000)\n",
    "\n",
    "    print(start, end)\n",
    "\n",
    "    waveform = waveform[:, start:end]\n",
    "\n",
    "    # path to alignment file\n",
    "    alignment_path = os.path.join(alignments_folder_path, \n",
    "                                  audio_collection, \n",
    "                                  row['filename'] + '.csv')\n",
    "    \n",
    "    # load alignment file\n",
    "    alignment = pd.read_csv(alignment_path)\n",
    "\n",
    "    # path to notes file\n",
    "    notes_path = os.path.join(notes_folder_path,\n",
    "                                audio_collection,\n",
    "                                row['filename'] + '.csv')\n",
    "    \n",
    "    # load notes file\n",
    "    notes = pd.read_csv(notes_path)\n",
    "\n",
    "    # combination of alignment and notes (they are in order)\n",
    "    note_alignment = pd.concat([notes, alignment], axis=1)\n",
    "\n",
    "\n",
    "    # create a new wavefrom based on the notes and alignment\n",
    "    new_waveform = np.zeros_like(waveform)\n",
    "    \n",
    "    # intialize a piano roll\n",
    "    # piano roll frequency is 64 Hz\n",
    "    piano_roll = np.zeros((128, 64))\n",
    "    \n",
    "    for _, note_row in note_alignment.iterrows():\n",
    "        # note has the following fields:\n",
    "        # onset,offset,pitch,velocity, start, end\n",
    "        # start and end are in seconds\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
<<<<<<< HEAD
    "        nstart = int(float(note_row['start']) * 16000)\n",
    "        nend = int(float(note_row['end']) * 16000)\n",
=======
    "        start = int(float(note_row['start'])) * 16000\n",
    "        end = int(float(note_row['end'])) * 16000\n",
>>>>>>> 5b64702 (preprocess update)
    "\n",
    "        if nstart == nend:\n",
    "            continue\n",
    "\n",
    "        #print(start, end)\n",
    "\n",
    "        # generate a new waveform for the note\n",
    "        note = note_row['pitch']\n",
    "        note = 440 * 2 ** ((note - 69) / 12)\n",
    "        # use numpy to generate a sine wave\n",
    "        note = np.sin(np.arange(nend - nstart) / 16000 * 2 * np.pi * note)\n",
    "\n",
    "        # add the note to the new waveform\n",
    "        new_waveform[:, nstart:nend] += note\n",
    "        # normalize the new waveform\n",
    "\n",
    "        # add some noise to the new waveform (0.1 of the note)\n",
    "        noise = np.random.random(nend - nstart) * 0.1 * np.abs(note).max()\n",
    "        new_waveform[:, nstart:nend] += noise\n",
    "\n",
    "        # add the note to the piano roll\n",
    "        nstart = int(nstart*64/16000)\n",
    "        nend = int((nend)*64/16000) + 1\n",
    "        piano_roll[int(note_row['pitch']), nstart:nend] = 1\n",
    "\n",
    "    assert waveform.shape == new_waveform.shape\n",
    "    assert waveform.shape[1] == end - start\n",
    "\n",
    "\n",
    "    # normalize the new waveform\n",
    "    new_waveform = new_waveform / np.abs(new_waveform).max()\n",
    "\n",
    "        \n",
    "\n",
    "    # save the waveform\n",
    "    new_audio_filename = row['filename'] + '.wav'\n",
    "    new_audio_path = os.path.join(outuput_audio, new_audio_filename)\n",
    "    torchaudio.save(new_audio_path, waveform, 16000)\n",
    "\n",
    "\n",
    "\n",
    "    # save the synthesized waveform\n",
    "    new_syn_filename = row['filename'] + '.wav'\n",
    "    new_syn_path = os.path.join(output_synthesized, new_syn_filename)\n",
    "    torchaudio.save(new_syn_path, torch.from_numpy(new_waveform), 16000)\n",
    "\n",
    "    # save the piano roll\n",
    "    new_proll_filename = row['filename'] + '.npy'\n",
    "    new_proll_path = os.path.join(output_proll, new_proll_filename)\n",
    "    np.save(new_proll_path, piano_roll)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haze_test_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
