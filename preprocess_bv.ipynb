{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Define the paths to the data files and folders\n",
    "dataset_folder_path = './data/bach-violin-dataset-v1.0/'\n",
    "audio_csv_path = os.path.join(dataset_folder_path, 'audio.csv')\n",
    "info_csv_path = os.path.join(dataset_folder_path, 'info.csv')\n",
    "audio_folder_path = os.path.join(dataset_folder_path, 'audio')\n",
    "alignments_folder_path = os.path.join(dataset_folder_path, 'alignments')\n",
    "notes_folder_path = os.path.join(dataset_folder_path, 'notes')\n",
    "\n",
    "# output folder\n",
    "output_folder_path = './data/bv_processed2'\n",
    "outuput_audio = os.path.join(output_folder_path, 'audio')\n",
    "output_synthesized = os.path.join(output_folder_path, 'synthesized') # synthesized piano roll\n",
    "output_proll = os.path.join(output_folder_path, 'proll') \n",
    "\n",
    "# Load the audio metadata from the audio.csv file into a pandas DataFrame\n",
    "audio_metadata = pd.read_csv(audio_csv_path)\n",
    "\n",
    "# Load the performance metadata from the info.csv file into a pandas DataFrame\n",
    "performance_metadata = pd.read_csv(info_csv_path)\n",
    "\n",
    "# Loop through the rows of the performance metadata DataFrame\n",
    "for _, row in performance_metadata.iterrows():\n",
    "    # row has the following fields:\n",
    "    # filename,collection,violinist,violinist_name,work,title,mov,movement,source_filename,start,end,length,repeat1,repeat2,score_filename,baroque_tuning\n",
    "\n",
    "    # load audio file\n",
    "    audio_filename = row['source_filename']\n",
    "    if not audio_filename.endswith('.mp3'):\n",
    "        continue\n",
    "\n",
    "    # audio collection\n",
    "    audio_collection = row['collection']\n",
    "\n",
    "    # path to audio file\n",
    "    audio_path = os.path.join(audio_folder_path, audio_collection, audio_filename)\n",
    "\n",
    "    # load audio file\n",
    "    waveform, sample_rate = torchaudio.load(audio_path)\n",
    "\n",
    "    # downsample and convert to mono\n",
    "    waveform = torchaudio.transforms.Resample(sample_rate, 16000)(waveform)\n",
    "    waveform = waveform.mean(0, keepdim=True)\n",
    "\n",
    "    # trim the waveform based on movement start and end\n",
    "    # start and end are in the format \"h:mm:ss\"\n",
    "    start = row['start']\n",
    "    end = row['end']\n",
    "\n",
    "    # start in seconds\n",
    "    start = start.split(':')\n",
    "    start = int(start[0]) * 3600 + int(start[1]) * 60 + int(start[2])\n",
    "\n",
    "    # end in seconds\n",
    "    end = end.split(':')\n",
    "    end = int(end[0]) * 3600 + int(end[1]) * 60 + int(end[2])\n",
    "\n",
    "    # trim the waveform\n",
    "    start = int(start * 16000)\n",
    "    end = int(end * 16000)\n",
    "\n",
    "    waveform = waveform[:, start:end]\n",
    "\n",
    "    # path to alignment file\n",
    "    alignment_path = os.path.join(alignments_folder_path, \n",
    "                                  audio_collection, \n",
    "                                  row['filename'] + '.csv')\n",
    "    \n",
    "    # load alignment file\n",
    "    alignment = pd.read_csv(alignment_path)\n",
    "\n",
    "    # path to notes file\n",
    "    notes_path = os.path.join(notes_folder_path,\n",
    "                                audio_collection,\n",
    "                                row['filename'] + '.csv')\n",
    "    \n",
    "    # load notes file\n",
    "    notes = pd.read_csv(notes_path)\n",
    "\n",
    "    # combination of alignment and notes (they are in order)\n",
    "    note_alignment = pd.concat([notes, alignment], axis=1)\n",
    "\n",
    "\n",
    "    # create a new wavefrom based on the notes and alignment\n",
    "    new_waveform = np.zeros_like(waveform)\n",
    "    \n",
    "    # intialize a piano roll\n",
    "    # piano roll frequency is 64 Hz\n",
    "    piano_roll = np.zeros((128, 64))\n",
    "    \n",
    "    for _, note_row in note_alignment.iterrows():\n",
    "        # note has the following fields:\n",
    "        # onset,offset,pitch,velocity, start, end\n",
    "        # start and end are in seconds\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        start = int(float(note_row['start']) * 16000)\n",
    "        end = int(float(note_row['end']) * 16000)\n",
    "\n",
    "        if start == end:\n",
    "            continue\n",
    "\n",
    "        #print(start, end)\n",
    "\n",
    "        # generate a new waveform for the note\n",
    "        note = note_row['pitch']\n",
    "        note = 440 * 2 ** ((note - 69) / 12)\n",
    "        # use numpy to generate a sine wave\n",
    "        note = np.sin(np.arange(end - start) / 16000 * 2 * np.pi * note)\n",
    "\n",
    "        # add the note to the new waveform\n",
    "        new_waveform[:, start:end] += note\n",
    "        # normalize the new waveform\n",
    "\n",
    "        # add some noise to the new waveform (0.1 of the note)\n",
    "        noise = np.random.random(end - start) * 0.1 * np.abs(note).max()\n",
    "        new_waveform[:, start:end] += noise\n",
    "\n",
    "        # add the note to the piano roll\n",
    "        start = int(start*64/16000)\n",
    "        end = int((end)*64/16000) + 1\n",
    "        piano_roll[int(note_row['pitch']), start:end] = 1\n",
    "\n",
    "\n",
    "    # normalize the new waveform\n",
    "    new_waveform = new_waveform / np.abs(new_waveform).max()\n",
    "\n",
    "        \n",
    "\n",
    "    # save the waveform\n",
    "    new_audio_filename = row['filename'] + '.wav'\n",
    "    new_audio_path = os.path.join(outuput_audio, new_audio_filename)\n",
    "    torchaudio.save(new_audio_path, waveform, 16000)\n",
    "\n",
    "    # save the synthesized waveform\n",
    "    new_syn_filename = row['filename'] + '.wav'\n",
    "    new_syn_path = os.path.join(output_synthesized, new_syn_filename)\n",
    "    torchaudio.save(new_syn_path, torch.from_numpy(new_waveform), 16000)\n",
    "\n",
    "    # save the piano roll\n",
    "    new_proll_filename = row['filename'] + '.npy'\n",
    "    new_proll_path = os.path.join(output_proll, new_proll_filename)\n",
    "    np.save(new_proll_path, piano_roll)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haze_test_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
